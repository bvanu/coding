
/**Overview
We have N jobs each having some profit associated with it, and we want to gain maximum profit by selecting some non-conflicting jobs. Two jobs A and B represented as (startTime, endTime) by (startA, endA) and (startB, endB) are non-conflicting if either job A starts after job B ends which can be represented by condition startA >= endB, or if job B starts after job A ends which can be represented by startB >= endA.
We can observe that for each job, there are two options, either to schedule it or not. The total number of possible combinations with N jobs is 2^N2 
N. The brute force approach is to enumerate every possible combination. However, we want a better-optimized approach. We can achieve this by applying our definition for non-conflicting jobs. If we schedule the job at index i that ends at endTime[i], then all the jobs which have a startTime before endTime[i] can be discarded. The next job to schedule at index j should have a start time, startTime[j], such that startTime[j] >= endTime[i].

There are two key characteristics of this problem that we should take note of at this time. First, a job cannot be scheduled if a conflicting job has already been scheduled. In other words, each decision we make is affected by the previous decisions we have made. Second, the problem asks us to maximize the profit by scheduling non-conflicting jobs. These are two common characteristics of dynamic programming problems, and as such we will approach this problem using dynamic programming.

Approach 1: Top-Down Dynamic Programming + Binary Search
Intuition
Let's start at time zero, before the startTime of any job, at this point we can choose any job to schedule first. Once the first job has ended, we can iterate over all of the jobs and only consider scheduling those that start after the current time. The process of repeatedly iterating over the jobs array is very time-consuming and we can do better: if we sort our jobs according to start time, then we can apply binary search to find the next job. After sorting jobs according to startTime, to find the index of the first non-conflicting job, binary search for the endTime of the current job in the list of start times for all jobs.
For each job, we will try two options:
Schedule this job and move on to the next non-conflicting job using binary search.
Skip this job and move on to the next available job.
Then we can make an informed decision about whether we should schedule the job based on which of the above two options results in the greater profit.
This recursive approach will have repeated subproblems; this can be observed in the figure below. Notice, the subtree with root 22 is repeated signifying that we must solve this subproblem more than once. fig
To address this issue, the first time we calculate maxProfit for a certain position, we will store the value in an array; this value represents the maximum profit we can get from the jobs at indices from position to the end of the array. The next time we need to calculate maxProfit for this position, we can look up the result in constant time. This technique is known as memoization and it helps us avoid recalculating repeated subproblems.

Algorithm
Store the startTime, endTime and profit of each job in jobs.
Sort the jobs according to their starting time.
Iterate over jobs from left to right, where position is the index of the current job. For each job, we must compare two options:
i. Skip the current job (earn 0 profit) and move on to consider the job at the index position + 1.
ii. Schedule the current job (earn profit for the current job) and move on to the next non-conflicting job whose index is nextIndex. nextIndex is determined by using binary search in the startTime array.
Return the maximum profit of the two choices and record this profit in the array memo (memoization).
Implementation


Complexity Analysis
Let NN be the length of the jobs array.
Time complexity: O(NlogN)
Sorting jobs according to their starting time will take O(N\log N)O(NlogN).
The time complexity for the recursion (with memoization) is equal to the number of times findMaxProfit is called times the average time of findMaxProfit. The number of calls to findMaxProfit is 2*N2∗N because each non-memoized call will call findMaxProfit twice. Each memoized call will take O(1)O(1) time while for the non-memoized call, we will perform a binary search that takes O(log N)O(logN) time, hence the time complexity will be O(N\log N + N)O(NlogN+N).
The total time complexity is therefore equal to O(NlogN).

Space complexity: O(N)
Storing the starting time, ending time, and profit of each job will take 3\cdot N3⋅N space. Hence the complexity is O(N)O(N).
The space complexity of the sorting algorithm depends on the implementation of each programming language. For instance, in Java, the Arrays.sort() for primitives is implemented as a variant of quicksort algorithm whose space complexity is O(\log N)O(logN). In C++ sort() function provided by STL is a hybrid of Quick Sort, Heap Sort and Insertion Sort with the worst-case space complexity of O(\log N)O(logN). Thus the use of inbuilt sort() function adds O(\log N)O(logN) to space complexity.
The result for each position will be stored in memo and position can have the values from 00 to NN, thus the space required is O(N)O(N). Also, stack space in recursion is equal to the maximum number of active functions. In the scenario where every job is not scheduled, the function call stack will be of size NN.
The total space complexity is therefore equal to O(N)O(N).

**/

class Solution {
    // maximum number of jobs are 50000
    int[] memo = new int[50001];
    
    private int findNextJob(int[] startTime, int lastEndingTime) {
        int start = 0, end = startTime.length - 1, nextIndex = startTime.length;
        
        while (start <= end) {
            int mid = (start + end) / 2;
            if (startTime[mid] >= lastEndingTime) {
                nextIndex = mid;
                end = mid - 1;
            } else {
                start = mid + 1;
            }
        }
        return nextIndex;
    }
    
    private int findMaxProfit(List<List<Integer>> jobs, int[] startTime, int n, int position) {
        // 0 profit if we have already iterated over all the jobs
        if (position == n) {
            return 0;
        }
        
        // return result directly if it's calculated 
        if (memo[position] != -1) {
            return memo[position];
        }
        
        // nextIndex is the index of next non-conflicting job
        int nextIndex = findNextJob(startTime, jobs.get(position).get(1));
        
        // find the maximum profit of our two options: skipping or scheduling the current job
        int maxProfit = Math.max(findMaxProfit(jobs, startTime, n, position + 1), 
                        jobs.get(position).get(2) + findMaxProfit(jobs, startTime, n, nextIndex));
        
        // return maximum profit and also store it for future reference (memoization)
        return memo[position] = maxProfit;
    }
    
    public int jobScheduling(int[] startTime, int[] endTime, int[] profit) {
        List<List<Integer>> jobs = new ArrayList<>();
        
        // marking all values to -1 so that we can differentiate 
        // if we have already calculated the answer or not
        Arrays.fill(memo, -1);
        
        // storing job's details into one list 
        // this will help in sorting the jobs while maintaining the other parameters
        int length = profit.length;
        for (int i = 0; i < length; i++) {
            ArrayList<Integer> currJob = new ArrayList<>();
            currJob.add(startTime[i]);
            currJob.add(endTime[i]);
            currJob.add(profit[i]);
            jobs.add(currJob);
        }
        jobs.sort(Comparator.comparingInt(a -> a.get(0)));
        
        // binary search will be used in startTime so store it as separate list
        for (int i = 0; i < length; i++) {
            startTime[i] = jobs.get(i).get(0);
        }
        
        return findMaxProfit(jobs, startTime, length, 0);
    }
}
